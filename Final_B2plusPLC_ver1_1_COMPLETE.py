#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
B2+PLC: Proactive Latency Control for WebRTC Congestion Management
==================================================================

Copyright (c) 2025  Jin-Hyeong Lee, MD
ORCID: 0009-0008-8242-8444
Independent Researcher, South Korea
* Correspondence: ljh7534@gmail.com

Licensed under the MIT License.
See the LICENSE file in the project root for the full license text.

VERSION: 1.1-COMPLETE (Production Ready - All Issues Fixed)

FIXES IN THIS VERSION:
    - Issue 1: File naming consistency (OUTPUT_FILES centralized)
    - Issue 2: Function ordering (calculate_effect_sizes before usage)
    - Issue 3: Pandas float precision warnings eliminated

PAPER:
    "Medical Decision-Inspired Proactive Latecy Control for 
    Real Time Systems"

KEY FEATURES:
    1. Medical decision-making principles (pre-intervention, self-damping, multi-resource)
    2. Rigorous statistical validation (block bootstrap + Holm-Bonferroni)
    3. Complete reproducibility (manifest generation, seed management)
    4. Production-ready quality (all edge cases handled)

USAGE:
    # Quick test (2-3 minutes)
    python Final_B2plusPLC_ver1_1_COMPLETE.py --N 30000 --boot 300 --seed 4242
    
    # Full experiment (15-20 minutes)
    python Final_B2plusPLC_ver1_1_COMPLETE.py --N 100000 --boot 2000 --seed 4242

REQUIREMENTS:
    - Python 3.8+
    - numpy >= 1.20
    - pandas >= 1.3

DATE: 2025-10-28
"""

import argparse
import json
import sys
import subprocess
import numpy as np
import pandas as pd
from datetime import datetime
from pathlib import Path

# =============================================================================
# OUTPUT FILE NAMES (Issue 1 FIX: Centralized to prevent inconsistencies)
# =============================================================================
OUTPUT_FILES = {
    'summary': 'results_summary.csv',
    'tests': 'results_bootstrap_tests.csv',
    'block_tests': 'results_bootstrap_block_tests.csv',
    'sweep': 'results_lambda_sweep.csv',
    'ablation': 'results_ablation_summary.csv',
    'ablation_tests': 'results_ablation_bootstrap.csv',
    'effect_sizes': 'results_effect_sizes.csv',
    'manifest': 'run_manifest.json'
}

# =============================================================================
# CONFIGURATION PARAMETERS
# =============================================================================

# Simulation timing
DT = 0.02  # Control interval: 20 ms (‚âà50 Hz control/feedback loop)
           # Rationale: Matches typical WebRTC frame pacing and GCC feedback cadence
           #            observed in production deployments (Chromium/libwebrtc)
           # References: 
           #   - RFC 8868: Evaluation methodology for interactive media congestion control
           #     (provides evaluation guidelines; does not mandate specific sampling rate)
           #   - WebRTC implementation: https://webrtc.googlesource.com/src/
           #   - Practitioner literature: webrtcHacks GCC articles

RTT = 0.050  # Round-trip time: 50 ms (continental networks median)

# Delay components (ms)
NETWORK_DELAY_BASE = 35.0  # Base one-way propagation
CODEC_DELAY = 25.0         # Video encode/decode
RENDER_DELAY_BASE = 30.0   # Playout buffer + rendering

# Derived parameters
DELTA_T_BASE = NETWORK_DELAY_BASE + CODEC_DELAY + RENDER_DELAY_BASE  # 90 ms
COMPLIANCE_THRESHOLD = 100.0  # Perceptual quality threshold (ITU-T G.1010)
DELTA_T_TH = 95.0             # PLC intervention threshold (5 ms safety margin)

# WebRTC GCC parameters (from libwebrtc source)
GAMMA_OVERUSE = 12.5   # Delay gradient threshold (ms/s)
ALPHA_INCREASE = 1.05  # AIMD multiplicative increase (5%)
BETA_DECREASE = 0.85   # AIMD multiplicative decrease (15%)
MIN_BITRATE = 150.0    # Minimum rate (kbps)
MAX_BITRATE = 10000.0  # Maximum rate (kbps)

# PLC-specific parameters
ALPHA_EMA = 0.65               # EMA smoothing coefficient
LAMBDA_WEAK_DEFAULT = 0.30     # Damping parameter (dose-response)

# Control factors: PLC effect units ‚Üí delay reductions (ms)
NETWORK_CONTROL_FACTOR = 1.00  # Buffer adjustment (1:1)
RENDER_CONTROL_FACTOR = 1.00   # Frame budget (1:1)
SYSTEM_CONTROL_FACTOR = 0.50   # Priority/scheduling (conservative)

TOTAL_EFFECT_DAMPING = 0.30    # Global damping (when mode='damped')

K_P_MIN, K_P_MAX = 0.4, 1.5    # Self-damping gain bounds

# =============================================================================
# Utility: Heavy-tailed jitter generator
# =============================================================================
def heavy_tail_jitter(n, sigma_normal=7.5, sigma_spike=15.0, p_spike=0.1, seed=4242):
    """
    Generate heavy-tailed network jitter using mixture of Gaussians.
    
    Args:
        n: Number of samples
        sigma_normal: Std dev for typical jitter (90%)
        sigma_spike: Std dev for spike jitter (10%)
        p_spike: Probability of spike
        seed: Random seed
        
    Returns:
        Array of jitter values (ms)
    """
    rng = np.random.default_rng(seed)
    mask = rng.random(n) > p_spike
    jit = np.zeros(n, dtype=np.float64)  # Issue 3 FIX: Explicit dtype
    jit[mask] = rng.normal(0.0, sigma_normal, mask.sum())
    jit[~mask] = rng.normal(0.0, sigma_spike, (~mask).sum())
    return jit

# =============================================================================
# Classes
# =============================================================================
class RealisticWebRTCGCC:
    """Container for GCC rate state."""
    def __init__(self, init_rate=2000.0):
        self.rate = float(init_rate)

class ComponentConfig:
    """Configuration for PLC component activation."""
    def __init__(self, pre=True, self_damp=True, multi=True):
        self.pre = bool(pre)
        self.self_damp = bool(self_damp)
        self.multi = bool(multi)

class ConservativeGCCPLC:
    """
    Proactive Latency Control (PLC) enhancement layer.
    """
    def __init__(self, gcc: RealisticWebRTCGCC, cfg: ComponentConfig,
                 lambda_weak: float = LAMBDA_WEAK_DEFAULT,
                 alpha_ema: float = ALPHA_EMA,
                 debug: bool = False):
        self.gcc = gcc
        self.cfg = cfg
        self.lambda_weak = float(lambda_weak)
        self.alpha = float(alpha_ema)
        self.K_p = 1.0
        self.s_ema = None

        # Pre-intervention band [90, 95] ms
        self.band_low = DELTA_T_TH - 5.0
        self.band_high = DELTA_T_TH

        # Debug / stats
        self.debug = debug
        self.activation_stats = {
            'pre_activations': 0,
            'multi_activations': 0,
            'total_steps': 0,
            'total_effects': []
        }

    def control_step(self, current_e2e: float, base_network: float, t_now: float):
        """Execute one PLC control step."""
        self.activation_stats['total_steps'] += 1

        # EMA smoothing
        if self.s_ema is None:
            self.s_ema = current_e2e
        else:
            self.s_ema = self.alpha * current_e2e + (1.0 - self.alpha) * self.s_ema

        # Risk-averse gain adjustment (aka "self-damping" in text)
        # If s_ema > threshold (worsening): decrease K_p to avoid overshoot/competition with GCC
        # If s_ema < threshold (improving): increase K_p to accelerate convergence (within bounds)
        if self.cfg.self_damp:
            r = max(0.7, min(1.3, self.s_ema / DELTA_T_TH))
            self.K_p = np.clip(self.K_p * (1.0 - 0.30 * (r - 1.0)), K_P_MIN, K_P_MAX)

        # Pre-intervention gating
        in_pre_band = (self.band_low <= self.s_ema <= self.band_high)

        g_gate = 0.0
        if self.cfg.pre and in_pre_band:
            # Pre-intervention: Î∞¥Îìú ÎÇ¥ÏóêÏÑúÎßå Í∞ïÌïú Í≤åÏù¥Ìä∏
            g_gate = self.lambda_weak
        elif (not self.cfg.pre) and (self.cfg.self_damp or self.cfg.multi):
            # PreÍ∞Ä ÏóÜÎäî Íµ¨ÏÑ±ÏóêÏÑúÎßå ÏïΩÌïú Í≤åÏù¥Ìä∏ ÌóàÏö©(0.15 √ó Œª)
            g_gate = 0.15 * self.lambda_weak

        # Multi-resource / Pre / Self Ìö®Í≥º
        eff_B = 0.0
        eff_F = 0.0
        eff_P = 0.0

        # Threshold ÎåÄÎπÑ Î∂ÄÌò∏ ÏûàÎäî Ïò§Ï∞®
        err_from_th = self.s_ema - DELTA_T_TH   # >0: Ï¥àÍ≥º(reactive), <0: Ïó¨Ïú†(pre)
        pre_err     = max(0.0, -err_from_th)    # pre-band ÎÇ¥ Ïó¨Ïú†Îüâ
        over_err    = max(0.0,  err_from_th)    # ÏûÑÍ≥Ñ Ï¥àÍ≥ºÎüâ

        # Exclusive precedence: Multi > Pre > Self
        if self.cfg.multi:
            # Multi: responds both in pre-band and over threshold
            if over_err > 0.0:
                eff_B = over_err * 0.15
                eff_F = over_err * 0.10
                eff_P = over_err * 0.05
            elif in_pre_band and pre_err > 0.0:
                eff_B = pre_err * 0.15
                eff_F = pre_err * 0.10
                eff_P = pre_err * 0.05
        elif self.cfg.pre and in_pre_band and pre_err > 0.0:
            eff_B = pre_err * 0.08
        elif self.cfg.self_damp:
            if over_err > 0.0:
                eff_B = over_err * 0.08 * self.K_p
            elif pre_err > 0.0:
                eff_B = pre_err * 0.08 * self.K_p

        # Scale
        if self.cfg.self_damp:
            scale = self.K_p
        else:
            scale = 1.0

        # Debug
        if self.debug and self.activation_stats['total_steps'] % 1000 == 0:
            print(f"[PLC Debug t={t_now:.2f}s] "
                  f"s_ema={self.s_ema:.2f}ms, K_p={self.K_p:.3f}, "
                  f"g={g_gate:.3f}, in_pre_band={in_pre_band}, "
                  f"err_from_th={err_from_th:.3f}, pre_err={pre_err:.3f}, over_err={over_err:.3f}, "
                  f"eff_B={eff_B:.3f}, eff_F={eff_F:.3f}, eff_P={eff_P:.3f}")

        # Í≤åÏù¥Ìä∏ Ï¥ù onÏú®Í≥º pre Ï†ÑÏö© onÏú®ÏùÑ Î∂ÑÎ¶¨
        if g_gate > 0:
            self.activation_stats.setdefault('gate_on', 0)
            self.activation_stats['gate_on'] += 1

        # 'pre' Î∞¥Îìú Ï∂©Ï°±ÏúºÎ°ú Ïù∏Ìï¥ pre Í≤åÏù¥Ìä∏Í∞Ä Ïã§Ï†úÎ°ú ÏºúÏ°åÏùÑ ÎïåÎßå Ïπ¥Ïö¥Ìä∏
        if (self.cfg.pre and in_pre_band):
            self.activation_stats['pre_activations'] += 1

        if (eff_B > 0.0) or (eff_F > 0.0) or (eff_P > 0.0):
            self.activation_stats['multi_activations'] += 1
            total_eff = eff_B + eff_F + eff_P
            self.activation_stats['total_effects'].append(total_eff)

        return {
            'g': g_gate,
            'scale': scale,
            'effects': {
                'buffer': eff_B,
                'frame': eff_F,
                'priority': eff_P,
            }
        }

    def get_stats(self):
        """PLC ÌôúÏÑ±Ìôî ÌÜµÍ≥Ñ Î∞òÌôò"""
        total = self.activation_stats['total_steps']
        gate_on = self.activation_stats.get('gate_on', 0)
        return {
            'pre_activation_rate': self.activation_stats['pre_activations'] / total if total else 0.0,
            'gate_on_rate': gate_on / total if total else 0.0,
            'multi_activation_rate': self.activation_stats['multi_activations'] / total if total else 0.0,
            'mean_effect': np.mean(self.activation_stats['total_effects']) if self.activation_stats['total_effects'] else 0.0,
            'max_effect': np.max(self.activation_stats['total_effects']) if self.activation_stats['total_effects'] else 0.0
        }

class SimpleKalman:
    """1D Kalman filter for delay gradient estimation."""
    def __init__(self, q=4.0, r=25.0, x0=0.0, p0=10.0):
        self.q = q
        self.r = r
        self.x = x0
        self.p = p0
        
    def update(self, z):
        """Update with new measurement z."""
        x_prior = self.x
        p_prior = self.p + self.q
        k = p_prior / (p_prior + self.r)
        self.x = x_prior + k * (z - x_prior)
        self.p = (1 - k) * p_prior
        return self.x

# =============================================================================
# Simulators
# =============================================================================
def simulate_gcc_B2(network_jitter, seed=0, loss_p_base=0.005):
    """Simulate baseline B2 algorithm (Kalman trend + loss-aware AIMD)."""
    rng = np.random.default_rng(seed)
    n = len(network_jitter)
    gcc = RealisticWebRTCGCC()
    kf = SimpleKalman(q=4.0, r=25.0, x0=0.0, p0=10.0)
    
    network_delays = np.zeros(n, dtype=np.float64)  # Issue 3 FIX
    e2e = np.zeros(n, dtype=np.float64)
    rate = gcc.rate
    over = 0
    under = 0
    last_upd = 0.0
    
    for i in range(n):
        t = i * DT
        base_net = max(25.0, NETWORK_DELAY_BASE + network_jitter[i])
        
        # Kalman trend
        trend_obs = base_net if i == 0 else (base_net - network_delays[i-1])
        trend_est = kf.update(trend_obs)
        
        # State detection
        if trend_est > GAMMA_OVERUSE:
            over += 1
            under = 0
            state = 'decrease'
        elif trend_est < -GAMMA_OVERUSE / 2:
            under += 1
            over = 0
            state = 'increase'
        else:
            over = max(0, over - 1)
            under = max(0, under - 1)
            state = 'hold'
        
        # Loss detection
        loss_p = loss_p_base + max(0.0, (base_net - 40.0)) * 0.0002
        if rng.random() < loss_p:
            state = 'decrease'
        
        # AIMD rate update (every RTT)
        if t - last_upd >= RTT:
            last_upd = t
            if state == 'decrease':
                rate *= BETA_DECREASE
            elif state == 'increase':
                rate *= ALPHA_INCREASE
            rate = np.clip(rate, MIN_BITRATE, MAX_BITRATE)
        
        # Rate ‚Üí delay mapping
        if state == 'decrease':
            net_red = min(7.0, (2000.0 - rate) / 300.0)
        elif state == 'increase':
            net_red = -min(4.0, (rate - 2000.0) / 450.0)
        else:
            net_red = 0.0
        
        eff_red = net_red * 0.35
        
        # Oscillation noise
        osc = 0.0
        if over > 0:
            osc = rng.normal(0, 2.8)
        elif under > 0:
            osc = rng.normal(0, 1.8)
        
        controlled_net = max(25.0, base_net - eff_red + osc)
        
        # Smoothing
        if i > 0:
            controlled_net = 0.7 * controlled_net + 0.3 * network_delays[i-1]
        
        network_delays[i] = controlled_net
        e2e[i] = controlled_net + CODEC_DELAY + RENDER_DELAY_BASE
    
    return e2e

def simulate_plc_on_B2(network_jitter, cfg: ComponentConfig,
                       lambda_weak=LAMBDA_WEAK_DEFAULT,
                       init_seed=1234, total_effect_mode='none', debug=False):
    """Simulate B2 + PLC enhancement."""
    n = len(network_jitter)
    gcc = RealisticWebRTCGCC()
    kf = SimpleKalman(q=4.0, r=25.0, x0=0.0, p0=10.0)
    plc = ConservativeGCCPLC(gcc, cfg, lambda_weak=lambda_weak, alpha_ema=ALPHA_EMA, debug=debug)
    
    rate = gcc.rate
    over = 0
    under = 0
    last_upd = 0.0
    e2e = np.zeros(n, dtype=np.float64)  # Issue 3 FIX
    net_del = np.zeros(n, dtype=np.float64)
    current = DELTA_T_BASE
    rng = np.random.default_rng(init_seed)
    
    for i in range(n):
        t = i * DT
        base_net = max(25.0, NETWORK_DELAY_BASE + network_jitter[i])
        
        # PLC control step
        res = plc.control_step(current, base_net, t)
        eff = res['effects']
        g = res['g']
        scale = res.get('scale', 1.0)

        net_eff   = eff['buffer']   * NETWORK_CONTROL_FACTOR * g * scale
        frame_eff = eff['frame']    * RENDER_CONTROL_FACTOR  * g * scale
        prio_eff  = eff['priority'] * SYSTEM_CONTROL_FACTOR  * g * scale
        
        # B2 dynamics (same as baseline)
        trend_obs = base_net if i == 0 else (base_net - net_del[i-1])
        trend_est = kf.update(trend_obs)
        
        if trend_est > GAMMA_OVERUSE:
            over += 1
            under = 0
            state = 'decrease'
        elif trend_est < -GAMMA_OVERUSE / 2:
            under += 1
            over = 0
            state = 'increase'
        else:
            over = max(0, over - 1)
            under = max(0, under - 1)
            state = 'hold'
        
        loss_p = 0.005 + max(0.0, (base_net - 40.0)) * 0.0002
        if rng.random() < loss_p:
            state = 'decrease'
        
        if t - last_upd >= RTT:
            last_upd = t
            if state == 'decrease':
                rate *= BETA_DECREASE
            elif state == 'increase':
                rate *= ALPHA_INCREASE
            rate = np.clip(rate, MIN_BITRATE, MAX_BITRATE)
        
        if state == 'decrease':
            net_red = min(7.0, (2000.0 - rate) / 300.0)
        elif state == 'increase':
            net_red = -min(4.0, (rate - 2000.0) / 450.0)
        else:
            net_red = 0.0
        
        eff_red_B2 = net_red * 0.35
        
        osc = 0.0
        if over > 0:
            osc = rng.normal(0, 2.8)
        elif under > 0:
            osc = rng.normal(0, 1.8)
        
        controlled_net = max(25.0, base_net - eff_red_B2 + osc)
        # Î¶¨ÏÜåÏä§Î≥Ñ Îã®Ïùº Ï†ÅÏö©(ÎÑ§Ìä∏ÏõåÌÅ¨)
        controlled_net -= net_eff
        controlled_net = max(25.0, controlled_net)
        
        if i > 0:
            controlled_net = 0.6 * controlled_net + 0.4 * net_del[i-1]
        
        net_del[i] = controlled_net
        # Î¶¨ÏÜåÏä§Î≥Ñ Îã®Ïùº Ï†ÅÏö©(Î†åÎçî)
        controlled_render = max(16.7, RENDER_DELAY_BASE - frame_eff)
        
        # E2E Í≥ÑÏÇ∞: ÏãúÏä§ÌÖú(Ïö∞ÏÑ†ÏàúÏúÑ/Ïä§ÏºÄÏ§ÑÎßÅ) Ìö®Í≥ºÎßå Ìïú Î≤à Ï†ÅÏö©
        current = max(78.0, controlled_net + CODEC_DELAY + controlled_render - prio_eff)        
        e2e[i] = current

    # Debug Î™®ÎìúÏùº Îïå ÌÜµÍ≥Ñ Ï∂úÎ†•
    if debug:
        stats = plc.get_stats()
        print(f"\n[PLC Statistics]")
        print(f"  Pre-intervention activation rate: {stats['pre_activation_rate']:.2%}")
        print(f"  Multi-resource activation rate: {stats['multi_activation_rate']:.2%}")
        print(f"  Mean effect when active: {stats['mean_effect']:.4f} ms")
        print(f"  Max effect: {stats['max_effect']:.4f} ms")
    
    return e2e

# =============================================================================
# Metrics & Statistics (Issue 2 FIX: calculate_effect_sizes defined BEFORE usage)
# =============================================================================
def metrics(x):
    """Calculate performance metrics for latency array."""
    return {
        'mean': float(np.mean(x)),
        'std': float(np.std(x)),
        'variance': float(np.var(x)),
        'p99': float(np.percentile(x, 99)),
        'compliance_%': float(np.mean(x <= COMPLIANCE_THRESHOLD) * 100.0)
    }

def cohens_d_paired(a, b):
    """
    Calculate Cohen's d_z for paired samples.
    
    d_z = mean(diff) / sd(diff)
    
    Interpretation:
        |d_z| < 0.2: negligible
        0.2 ‚â§ |d_z| < 0.5: small
        0.5 ‚â§ |d_z| < 0.8: medium
        |d_z| ‚â• 0.8: large
    """
    diff = a - b
    return float(np.mean(diff) / np.std(diff, ddof=1))

def interpret_d(d):
    """Interpret Cohen's d magnitude."""
    d_abs = abs(d)
    if d_abs < 0.2:
        return 'negligible'
    elif d_abs < 0.5:
        return 'small'
    elif d_abs < 0.8:
        return 'medium'
    else:
        return 'large'

def calculate_effect_sizes(lat_B2, lat_PLC):
    """
    Generate comprehensive effect size table for all metrics.
    
    Issue 2 FIX: This function is now defined BEFORE it's used in run_experiment.
    
    Returns:
        DataFrame with Cohen's d_z for each metric
    """
    effects = []
    
    # Mean latency
    d_mean = cohens_d_paired(lat_B2, lat_PLC)
    effects.append({
        'metric': 'Mean latency',
        'cohens_d_z': d_mean,
        'interpretation': interpret_d(d_mean),
        'direction': 'PLC improves (lower)' if d_mean > 0 else 'B2 better'
    })
    
    # Std. deviation (per-sample absolute deviations) ‚Äî robust than squared
    mean_B2 = np.mean(lat_B2)
    mean_PLC = np.mean(lat_PLC)
    std_B2_samples = np.abs(lat_B2 - mean_B2)
    std_PLC_samples = np.abs(lat_PLC - mean_PLC)
    d_std = cohens_d_paired(std_B2_samples, std_PLC_samples)
    effects.append({
        'metric': 'Std (abs dev)',
        'cohens_d_z': d_std,
        'interpretation': interpret_d(d_std),
        'direction': 'PLC improves (lower)' if d_std > 0 else 'B2 better'
    })
    
    # p99 (bootstrap-based, winsorized SE for robustness)
    p99_B2 = np.percentile(lat_B2, 99)
    p99_PLC = np.percentile(lat_PLC, 99)
    
    # Bootstrap SE estimation
    rng = np.random.default_rng(2025)
    n_boot = 1000
    n = len(lat_B2)

    boot_p99_B2 = []
    boot_p99_PLC = []
    for _ in range(n_boot):
        idx = rng.integers(0, n, n)
        boot_p99_B2.append(np.percentile(lat_B2[idx], 99))
        boot_p99_PLC.append(np.percentile(lat_PLC[idx], 99))
       
    boot_p99_B2 = np.array(boot_p99_B2)
    boot_p99_PLC = np.array(boot_p99_PLC)

    # Paired differenceÏùò ÌëúÏ§ÄÌé∏Ï∞® ÏÇ¨Ïö©
    boot_diffs = boot_p99_B2 - boot_p99_PLC
    d_p99 = (p99_B2 - p99_PLC) / np.std(boot_diffs, ddof=1)
    
    effects.append({
        'metric': 'p99 latency',
        'cohens_d_z': float(d_p99),
        'interpretation': interpret_d(d_p99),
        'direction': 'PLC improves (lower)' if d_p99 > 0 else 'B2 better',
        'warning': 'Large d_z; interpret with caution' if abs(d_p99) > 3 else ''
    })

    # >>> ADD THIS WARNING LINE <<<
    if abs(d_p99) > 3:
        print("Note: p99 Cohen's d_z is very large; interpret with caution ‚Äî "
               "percentiles and bootstrap SE can inflate d_z.")        
    
    df = pd.DataFrame(effects)
    return df

def paired_bootstrap_diff(fn, a, b, n_boot=2000, seed=2025):
    """Standard paired bootstrap."""
    rng = np.random.default_rng(seed)
    n = len(a)
    diffs = np.empty(n_boot, dtype=np.float64)  # Issue 3 FIX
    
    for i in range(n_boot):
        idx = rng.integers(0, n, n)
        diffs[i] = fn(a[idx]) - fn(b[idx])
    
    diffs.sort()
    md = float(np.mean(diffs))
    ci = (float(diffs[int(0.025 * n_boot)]), float(diffs[int(0.975 * n_boot) - 1]))
    p = 2.0 * min(np.mean(diffs <= 0.0), np.mean(diffs >= 0.0))
    return md, ci, float(min(1.0, p))

def paired_block_bootstrap_diff(fn, a, b, block=100, n_boot=1000, seed=3030):
    """Paired circular block bootstrap for time-series data."""
    rng = np.random.default_rng(seed)
    n = len(a)
    m = int(np.ceil(n / block))
    diffs = np.empty(n_boot, dtype=np.float64)  # Issue 3 FIX
    
    for i in range(n_boot):
        idx_list = []
        for _ in range(m):
            start = rng.integers(0, n)
            idx_block = (np.arange(start, start + block) % n)
            idx_list.append(idx_block)
        idx = np.concatenate(idx_list)[:n]
        diffs[i] = fn(a[idx]) - fn(b[idx])
    
    diffs.sort()
    md = float(np.mean(diffs))
    ci = (float(diffs[int(0.025 * n_boot)]), float(diffs[int(0.975 * n_boot) - 1]))
    p = 2.0 * min(np.mean(diffs <= 0.0), np.mean(diffs >= 0.0))
    return md, ci, float(min(1.0, p))

def holm_bonferroni(p_values):
    """Holm-Bonferroni multiple testing correction."""
    m = len(p_values)
    idx = sorted(range(m), key=lambda i: p_values[i])
    adj = [0.0] * m
    run_max = 0.0
    
    for rank, i in enumerate(idx):
        val = min((m - rank) * p_values[i], 1.0)
        run_max = max(run_max, val)
        adj[i] = run_max
    
    return adj

# =============================================================================
# Manifest Generation
# =============================================================================
def generate_manifest(args):
    """Generate run_manifest.json with complete reproducibility metadata."""
    # Get git info if available
    try:
        git_hash = subprocess.check_output(
            ['git', 'rev-parse', 'HEAD'],
            stderr=subprocess.DEVNULL
        ).decode('ascii').strip()
        
        git_dirty = subprocess.check_output(
            ['git', 'status', '--porcelain'],
            stderr=subprocess.DEVNULL
        ).decode('ascii').strip() != ''
    except:
        git_hash = 'N/A (not a git repository)'
        git_dirty = False
    
    manifest = {
        'metadata': {
            'timestamp': datetime.now().isoformat(),
            'script_version': '1.1-COMPLETE',
            'script_name': 'Final_B2plusPLC_ver1_1_COMPLETE.py',
            'git_commit': git_hash,
            'git_dirty': git_dirty,
            'python_version': sys.version,
            'numpy_version': np.__version__,
            'pandas_version': pd.__version__,
        },
        'arguments': {
            'N': args.N,
            'seed': args.seed,
            'boot': args.boot,
            'lambda_vals': args.lambda_vals,
            'total_effect_mode': args.total_effect_mode,
            'block_sizes': args.block_sizes,
            'debug': args.debug
        },
        'configuration': {
            'DT': DT,
            'RTT': RTT,
            'NETWORK_DELAY_BASE': NETWORK_DELAY_BASE,
            'CODEC_DELAY': CODEC_DELAY,
            'RENDER_DELAY_BASE': RENDER_DELAY_BASE,
            'DELTA_T_BASE': DELTA_T_BASE,
            'COMPLIANCE_THRESHOLD': COMPLIANCE_THRESHOLD,
            'DELTA_T_TH': DELTA_T_TH,
            'GAMMA_OVERUSE': GAMMA_OVERUSE,
            'ALPHA_INCREASE': ALPHA_INCREASE,
            'BETA_DECREASE': BETA_DECREASE,
            'LAMBDA_WEAK_DEFAULT': LAMBDA_WEAK_DEFAULT,
            'ALPHA_EMA': ALPHA_EMA
        },
        'outputs': OUTPUT_FILES  # Issue 1 FIX: Use centralized names
    }
    
    # Issue 1 FIX: Use OUTPUT_FILES dictionary
    with open(OUTPUT_FILES['manifest'], 'w') as f:
        json.dump(manifest, f, indent=2)
    
    print(f"‚úì Reproducibility manifest saved: {OUTPUT_FILES['manifest']}")

# =============================================================================
# CLI Validation
# =============================================================================
def validate_args(args):
    """Validate command-line arguments."""
    errors = []
    warnings = []
    
    # Validate N
    if args.N <= 0:
        errors.append(f"N must be positive, got {args.N}")
    elif args.N < 10000:
        warnings.append(f"N={args.N} may be too small for reliable statistics (recommend N‚â•10,000)")
    
    # Validate boot
    if args.boot <= 0:
        errors.append(f"boot must be positive, got {args.boot}")
    elif args.boot < 100:
        warnings.append(f"boot={args.boot} may be insufficient (recommend boot‚â•1,000)")
    
    # Validate seed
    if args.seed < 0:
        errors.append(f"seed must be non-negative, got {args.seed}")
    
    # Parse block_sizes
    try:
        block_list = [int(s.strip()) for s in args.block_sizes.split(',')]
        for b in block_list:
            if b <= 0:
                errors.append(f"block size must be positive, got {b}")
    except ValueError:
        errors.append(f"Invalid block_sizes format: '{args.block_sizes}'")
    
    # Parse lambda_vals
    try:
        lambda_list = [float(s.strip()) for s in args.lambda_vals.split(',')]
        for lam in lambda_list:
            if lam < 0 or lam > 1:
                warnings.append(f"lambda={lam} outside typical range [0,1]")
    except ValueError:
        errors.append(f"Invalid lambda_vals format: '{args.lambda_vals}'")
    
    # Validate total_effect_mode
    if args.total_effect_mode not in ['none', 'damped']:
        errors.append(f"total_effect_mode must be 'none' or 'damped', got '{args.total_effect_mode}'")
    
    if errors:
        print("\n" + "="*70)
        print("‚ùå ARGUMENT VALIDATION ERRORS:")
        print("="*70)
        for i, err in enumerate(errors, 1):
            print(f"  {i}. {err}")
        print("\nPlease fix the errors above and try again.")
        sys.exit(1)
    
    if warnings:
        print("\n" + "="*70)
        print("‚ö†Ô∏è  WARNINGS:")
        print("="*70)
        for i, warn in enumerate(warnings, 1):
            print(f"  {i}. {warn}")
        print("\nProceeding with simulation...")

# =============================================================================
# Main Experiment
# =============================================================================
def run_experiment(N=30000, seed=4242, boot=300, lambda_vals=(0.2, 0.3, 0.4, 0.5),
                   total_effect_mode='none', block_sizes=(100, 150, 200), debug=False):
    """Run complete PLC evaluation experiment."""
    
    print("\n" + "="*70)
    print("RUNNING B2+PLC EXPERIMENT")
    print("="*70)
    print(f"Configuration: N={N:,}, boot={boot:,}, seed={seed}")
    print(f"Total effect mode: {total_effect_mode}")
    print()
    
    # Generate paired jitter
    print("Generating network jitter...")
    net_jitter = heavy_tail_jitter(N, seed=seed)
    
    # Baselines
    print("Running B2 baseline simulation...")
    lat_B2 = simulate_gcc_B2(net_jitter, seed=seed + 1)
    
    print("Running B2+PLC full enhancement...")
    lat_full = simulate_plc_on_B2(
        net_jitter,
        ComponentConfig(True, True, True),
        lambda_weak=LAMBDA_WEAK_DEFAULT,
        init_seed=seed + 2,
        total_effect_mode=total_effect_mode,
        debug=debug
    )
    
    # Metrics
    M_B2 = metrics(lat_B2)
    M_full = metrics(lat_full)
    
    # Effect sizes (Issue 2 FIX: Now safe to call - defined earlier)
    print("Calculating effect sizes...")
    df_effect_sizes = calculate_effect_sizes(lat_B2, lat_full)
    
    # Issue 1 FIX: Use OUTPUT_FILES dictionary
    df_effect_sizes.to_csv(OUTPUT_FILES['effect_sizes'], index=False)
    
    # Bootstrap tests
    print("Running bootstrap statistical tests...")
    f_mean = lambda x: float(np.mean(x))
    f_p99 = lambda x: float(np.percentile(x, 99))
    f_var = lambda x: float(np.var(x))
    f_cmp = lambda x: float(np.mean(x <= COMPLIANCE_THRESHOLD) * 100.0)
    
    comps = [('mean', f_mean), ('p99', f_p99), ('variance', f_var), ('compliance_%', f_cmp)]
    
    # Standard bootstrap
    rows = []
    pvals = []
    for name, fn in comps:
        md, ci, p = paired_bootstrap_diff(fn, lat_B2, lat_full, n_boot=boot, seed=seed + 10)
        rows.append({
            'comparison': 'B2 vs B2+PLC(full)',
            'metric': name,
            'b2_minus_plc': md,
            'ci_lower': ci[0],
            'ci_upper': ci[1],
            'p_raw': p
        })
        pvals.append(p)
    
    p_adj = holm_bonferroni(pvals)
    for r, pa in zip(rows, p_adj):
        r['p_holm'] = pa
        r['significant_holm'] = (
            '***' if pa < 0.001 else ('**' if pa < 0.01 else ('*' if pa < 0.05 else 'ns'))
        )
    
    # Block bootstrap
    print("Running block bootstrap tests...")
    block_rows = []
    for blk in block_sizes:
        pv = []
        tmp = []
        for name, fn in comps:
            md, ci, p = paired_block_bootstrap_diff(
                fn, lat_B2, lat_full, block=int(blk), n_boot=boot, seed=seed + 30
            )
            tmp.append({
                'comparison': 'B2 vs B2+PLC(full)',
                'metric': name,
                'block': int(blk),
                'b2_minus_plc': md,
                'ci_lower': ci[0],
                'ci_upper': ci[1],
                'p_raw': p
            })
            pv.append(p)
        
        padj = holm_bonferroni(pv)
        for t, pa in zip(tmp, padj):
            t['p_holm'] = pa
            t['significant_holm'] = (
                '***' if pa < 0.001 else ('**' if pa < 0.01 else ('*' if pa < 0.05 else 'ns'))
            )
        block_rows.extend(tmp)
    
    # Lambda sweep (REPRODUCIBLE: reuse the SAME jitter for all Œª)
    print("Running lambda sensitivity analysis...")
    sweep_rows = []

    net_jitter_for_sweep = net_jitter  # ÎèôÏùº ÏãúÌÄÄÏä§ Ïû¨ÏÇ¨Ïö©
    for idx, lam in enumerate(lambda_vals):
        lat_lam = simulate_plc_on_B2(
            net_jitter_for_sweep,
            ComponentConfig(True, True, True),
            lambda_weak=float(lam),
            init_seed=seed + 1,   # Fixed: use consistent seed
            total_effect_mode=total_effect_mode
        )
        Mm = metrics(lat_lam)
        sweep_rows.append({'lambda': float(lam), **Mm})
    
    df_sweep = pd.DataFrame(sweep_rows).sort_values('lambda').reset_index(drop=True)

    # >>> ADD THIS SUMMARY LINE <<<
    print("Note: Œª controls gate strength, but effect magnitudes depend on threshold "
           "deviation (err_from_th). With fixed thresholds, Œª variations show limited "
           "impact on variance, while p99 may shift modestly.")
    
    # Ablations
    print("Running ablation study...")
    ab_cfgs = [
        ('Pre', ComponentConfig(True, False, False)),
        ('Self', ComponentConfig(False, True, False)),
        ('Multi', ComponentConfig(False, False, True)),
        ('Pre+Self', ComponentConfig(True, True, False)),
        ('Pre+Multi', ComponentConfig(True, False, True)),
        ('Self+Multi', ComponentConfig(False, True, True)),
        ('Full', ComponentConfig(True, True, True)),
    ]
    
    abl_rows = []
    abl_boot_rows = []
    
    # Ïû¨ÌòÑÏÑ±: ÎèôÏùº jitter + ÎèôÏùº ÎÇ¥Î∂Ä RNG ÏãúÌÄÄÏä§(Í≥µÏ†ï ÎπÑÍµê)
    SEED_JITTER   = seed
    SEED_INTERNAL = seed + 1

    for idx, (tag, cfg) in enumerate(ab_cfgs):
        lat = simulate_plc_on_B2(
            net_jitter,                 # ÎèôÏùºÌïú jitter
            cfg, 
            lambda_weak=LAMBDA_WEAK_DEFAULT,
            init_seed=SEED_INTERNAL,    # ‚òÖ Î™®Îì† ablation ÎèôÏùº ÎÇ¥Î∂Ä ÎÇúÏàò
            total_effect_mode=total_effect_mode,
            debug=False
        )
        Ms = metrics(lat)
        abl_rows.append({'variant': f'B2+PLC[{tag}]', **Ms})
        
        pv = []
        tmp = []
        for name, fn in comps:
            md, ci, p = paired_bootstrap_diff(fn, lat_B2, lat, n_boot=boot, seed=seed + 20)
            tmp.append({
                'variant': f'B2+PLC[{tag}]',
                'metric': name,
                'b2_minus_variant': md,
                'ci_lower': ci[0],
                'ci_upper': ci[1],
                'p_raw': p
            })
            pv.append(p)
        
        padj = holm_bonferroni(pv)
        for t, pa in zip(tmp, padj):
            t['p_holm'] = pa
            t['significant_holm'] = (
                '***' if pa < 0.001 else ('**' if pa < 0.01 else ('*' if pa < 0.05 else 'ns'))
            )
        abl_boot_rows.extend(tmp)
    
    # Save results (Issue 1 FIX: Use OUTPUT_FILES dictionary consistently)
    print("\nSaving results...")
    
    df_summary = pd.DataFrame([
        {'Variant': 'B2 (Kalman+Loss)', **M_B2},
        {'Variant': f'B2+PLC (Full, total={total_effect_mode})', **M_full}
    ])
    df_tests = pd.DataFrame(rows)
    df_block = pd.DataFrame(block_rows)
    df_abls = pd.DataFrame(abl_rows)
    df_abt = pd.DataFrame(abl_boot_rows)
    
    # Issue 1 FIX: All file saves use OUTPUT_FILES dictionary
    df_summary.to_csv(OUTPUT_FILES['summary'], index=False)
    df_tests.to_csv(OUTPUT_FILES['tests'], index=False)
    df_block.to_csv(OUTPUT_FILES['block_tests'], index=False)
    df_sweep.to_csv(OUTPUT_FILES['sweep'], index=False)
    df_abls.to_csv(OUTPUT_FILES['ablation'], index=False)
    df_abt.to_csv(OUTPUT_FILES['ablation_tests'], index=False)
    
    # Console summary
    print("\n" + "="*70)
    print("RESULTS SUMMARY - VERSION 1.1-COMPLETE")
    print("="*70)
    
    print("\n--- Performance Metrics ---")
    print(df_summary.to_string(index=False))
    
    print("\n--- Effect Sizes (Cohen's d_z) ---")
    print(df_effect_sizes.to_string(index=False))
    
    print("\n--- Statistical Tests (Bootstrap + Holm-Bonferroni) ---")
    print(df_tests[['metric', 'b2_minus_plc', 'ci_lower', 'ci_upper',
                    'p_holm', 'significant_holm']].to_string(index=False))
    
    variance_reduction_pct = 100 * (M_B2['variance'] - M_full['variance']) / M_B2['variance']
    print(f"\n‚úì Variance reduction: {variance_reduction_pct:.2f}%")
    
    print("\n--- Lambda Sweep Results ---")
    print(df_sweep[['lambda', 'variance', 'p99']].to_string(index=False))
    
    print("\n--- Ablation Summary ---")
    print(df_abls[['variant', 'variance', 'p99', 'compliance_%']].to_string(index=False))
    
    print("\n" + "="*70)
    print("‚úì ALL RESULTS SAVED TO CSV FILES")
    print("="*70)
    print("\nGenerated files:")
    for key, filename in OUTPUT_FILES.items():
        print(f"  - {filename}")
    print("\n‚úÖ Ready for publication!")
    
    return df_summary, df_tests, df_block, df_sweep, df_abls, df_abt, df_effect_sizes

# =============================================================================
# CLI
# =============================================================================
def parse_args():
    """Parse command-line arguments."""
    ap = argparse.ArgumentParser(
        description='B2+PLC Complete Simulation v1.1 (All Issues Fixed)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Quick test (2-3 minutes)
  python %(prog)s --N 30000 --boot 300 --seed 4242
  
  # Full experiment (15-20 minutes)
  python %(prog)s --N 100000 --boot 2000 --seed 4242
  
  # Custom lambda sweep
  python %(prog)s --N 50000 --lambda_vals 0.1,0.2,0.3,0.4,0.5
        """
    )
    
    ap.add_argument("--N", type=int, default=30000,
                    help="Number of simulation samples (default: 30000)")
    ap.add_argument("--seed", type=int, default=4242,
                    help="Base random seed (default: 4242)")
    ap.add_argument("--boot", type=int, default=300,
                    help="Bootstrap iterations (default: 300)")
    ap.add_argument("--lambda_vals", type=str, default="0.2,0.3,0.4,0.5",
                    help="Lambda values for sensitivity analysis (default: 0.2,0.3,0.4,0.5)")
    ap.add_argument("--total_effect_mode", type=str, default="none",
                    choices=["none", "damped"],
                    help="Total effect handling mode (default: none)")
    ap.add_argument("--block_sizes", type=str, default="100,150,200",
                    help="Block sizes for block bootstrap (default: 100,150,200)")
    ap.add_argument("--debug", action='store_true',
                    help="Enable PLC debug logging (sparse)")
    
    return ap.parse_args()

def main():
    """Main entry point."""
    print("="*70)
    print("B2+PLC Complete Simulation - Version 1.1-COMPLETE")
    print("All Issues Fixed: File naming, Function ordering, Float precision")
    print("="*70)
    print()
    
    args = parse_args()
    
    # Validate arguments
    validate_args(args)
    
    # Generate manifest
    generate_manifest(args)
    
    print("\n" + "="*70)
    print("CONFIGURATION")
    print("="*70)
    print(f"N: {args.N:,}")
    print(f"Bootstrap iterations: {args.boot:,}")
    print(f"Base seed: {args.seed}")
    print(f"Total effect mode: {args.total_effect_mode}")
    print(f"Block sizes: {args.block_sizes}")
    print(f"Debug mode: {args.debug}")
    
    # Parse arguments
    lam_list = tuple(float(s.strip()) for s in args.lambda_vals.split(",") if s.strip())
    block_sizes = tuple(int(s.strip()) for s in args.block_sizes.split(",") if s.strip())
    
    # Run experiment
    run_experiment(
        N=args.N,
        seed=args.seed,
        boot=args.boot,
        lambda_vals=lam_list,
        total_effect_mode=args.total_effect_mode,
        block_sizes=block_sizes,
        debug=args.debug
    )
    
    print("\n" + "="*70)
    print("üéâ SIMULATION COMPLETE!")
    print("="*70)
    print("\nNext steps:")
    print("1. Review CSV files for results")
    print("2. Generate figures using generate_figures_patched.py")
    print("3. Begin paper writing")
    print("\n‚úÖ Code is production-ready for publication!")

if __name__ == "__main__":
    main()
